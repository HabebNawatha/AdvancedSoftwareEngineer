{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for projects that contains .dbml files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_dbml_files(results):\n",
    "    filtered_results = [code_file for code_file in results if code_file['name'].endswith(\".dbml\")]\n",
    "    return filtered_results\n",
    "\n",
    "def search_code_with_dbml_files(access_token, page=1):\n",
    "    base_url = 'https://api.github.com/search/code'\n",
    "    headers = {\n",
    "        'Authorization': f'token {access_token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'q': f'filename:.dbml',\n",
    "        'per_page': 100,  # Adjust the number of results per page as needed\n",
    "        'page': page  # Specify the current page number\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        files = data.get('items', [])\n",
    "        return files\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Replace 'YOUR_ACCESS_TOKEN' with your actual GitHub access token\n",
    "access_token = 'YOUR_ACCESS_TOKEN'\n",
    "results = []\n",
    "\n",
    "# Perform multiple requests to gather all results\n",
    "visited_repositories = set()  # Store visited repositories\n",
    "\n",
    "# Perform multiple requests to gather all results\n",
    "for page_number in range(1, 4):  # Adjust the range based on the number of desired pages\n",
    "    page_results = search_code_with_dbml_files(access_token, page=page_number)\n",
    "    \n",
    "    for code_file in page_results:\n",
    "        repository_name = code_file['repository']['name']\n",
    "        if repository_name not in visited_repositories:\n",
    "            results.append(code_file)\n",
    "            visited_repositories.add(repository_name)\n",
    "\n",
    "\n",
    "print(f\"Total number of results: {len(results)}\")\n",
    "\n",
    "filtered_results = filter_dbml_files(results)\n",
    "print(f\"Total number of filtered results: {len(filtered_results)}\")\n",
    "\n",
    "\n",
    "# Save the repository URL and file URL in a CSV file\n",
    "csv_filename = \"filtered_files.csv\"\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    fieldnames = ['Repository', 'Repository URL', 'File', 'File URL']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for code_file in filtered_results:\n",
    "        writer.writerow({\n",
    "            'Repository': code_file['repository']['name'],\n",
    "            'Repository URL': code_file['repository']['html_url'],\n",
    "            'File': code_file['name'],\n",
    "            'File URL': code_file['html_url'],\n",
    "        })\n",
    "\n",
    "print(f\"Filtered files have been saved to {csv_filename}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the primary coding langauge for each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_csv = \"PATH_TO_csv_FILE/filtered_files.csv\"\n",
    "df = pd.read_csv(repositories_csv)\n",
    "repository_urls = df['Repository URL'].tolist()\n",
    "\n",
    "\n",
    "# Your GitHub personal access token\n",
    "access_token = \"YOUR_ACCESS_TOKEN\"\n",
    "\n",
    "# Headers with authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {access_token}\"\n",
    "}\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# Iterate through the repository URLs\n",
    "for repository_url in repository_urls:\n",
    "    # Parse repository owner and name from the URL\n",
    "    owner, repo_name = repository_url.split(\"/\")[-2:]\n",
    "\n",
    "    # GitHub API endpoint for repository information\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}\"\n",
    "\n",
    "    # Make a request to the GitHub API with authentication headers\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the primary programming language from the API response\n",
    "    primary_language = data.get(\"language\")\n",
    "\n",
    "    # Append data to the list\n",
    "    data_list.append({\"Repository URL\": repository_url, \"Primary Language\": primary_language})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df_results = pd.DataFrame(data_list)\n",
    "\n",
    "# Merge the results with the original df_testing based on the \"Repository URL\" column\n",
    "df = pd.merge(df, df_results, on=\"Repository URL\", how=\"left\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "csv_filename = \"output.csv\"\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "df.to_csv(csv_filename, index=False)  # Set index=False to exclude the index column from the CSV\n",
    "\n",
    "print(f\"DataFrame has been saved to {csv_filename}.\")\n",
    "\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
